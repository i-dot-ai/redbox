{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "import json\n",
    "import os\n",
    "import re\n",
    "from typing import List, Union\n",
    "\n",
    "import dotenv\n",
    "import pandas as pd\n",
    "from langchain.agents import (\n",
    "    AgentExecutor,\n",
    "    AgentOutputParser,\n",
    "    LLMSingleActionAgent,\n",
    "    Tool,\n",
    "    initialize_agent,\n",
    ")\n",
    "from langchain.agents.agent_toolkits import create_retriever_tool\n",
    "from langchain.chains.conversation.memory import ConversationBufferWindowMemory\n",
    "from langchain.chains.llm import LLMChain\n",
    "from langchain.chat_models import ChatAnthropic\n",
    "from langchain.prompts import BaseChatPromptTemplate\n",
    "from langchain.schema import AgentAction, AgentFinish, HumanMessage\n",
    "from langchain.utilities import PythonREPL, WikipediaAPIWrapper\n",
    "\n",
    "from redbox.llm.llm_base import LLMHandler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if os.path.basename(os.getcwd()) != \"10ds-ai-redbox\":\n",
    "    os.chdir(\"..\")\n",
    "    print(os.getcwd())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dotenv.load_dotenv(\".env\")\n",
    "# Grab it as a dictionary too for convenience\n",
    "ENV = dotenv.dotenv_values(\".env\")\n",
    "\n",
    "model_params = {\"max_tokens\": 4096, \"temperature\": 0.2}\n",
    "\n",
    "llm = ChatAnthropic(\n",
    "    anthropic_api_key=ENV[\"ANTHROPIC_API_KEY\"],\n",
    "    max_tokens=model_params[\"max_tokens\"],\n",
    "    temperature=model_params[\"temperature\"],\n",
    "    streaming=True,\n",
    ")\n",
    "\n",
    "llm_instance = LLMHandler(llm, user_uuid=\"dev\")\n",
    "\n",
    "url = \"https://docs.google.com/spreadsheets/d/e/2PACX-1vSf5yPnrU5Z_iIP7L3op6deIm5PeTrsr7RYgc82oBxzh4ZPoIa-JhTNr4YKECQA_AxDM616oVPPjQbr/pub?output=csv\"\n",
    "acronym_table = pd.read_csv(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def acronym(acronym=\"\"):\n",
    "    return json.dumps(\n",
    "        acronym_table.loc[acronym_table[\"Acronym\"] == acronym].to_dict(\"records\"),\n",
    "        indent=4,\n",
    "        ensure_ascii=False,\n",
    "    )\n",
    "\n",
    "\n",
    "def todays_date_and_time(_):\n",
    "    return datetime.datetime.now().isoformat(timespec=\"seconds\")\n",
    "\n",
    "\n",
    "# Tools\n",
    "\n",
    "python_repl = PythonREPL()\n",
    "python_repl_tool = Tool(\n",
    "    name=\"Python REPL\",\n",
    "    func=python_repl.run,\n",
    "    description=\"\"\"Useful for when you need to use python to answer a question. \\\n",
    "You should input python code. You MUST USE the datetime library for any date or time related questions.\"\"\",\n",
    ")\n",
    "\n",
    "wikipedia = WikipediaAPIWrapper()\n",
    "wikipedia_tool = Tool(\n",
    "    name=\"Wikipedia\",\n",
    "    func=wikipedia.run,\n",
    "    description=\"Useful for when you need to look up a topic that isn't defined in the provided sources\",\n",
    ")\n",
    "\n",
    "acronym_tool = Tool(\n",
    "    name=\"Acronym Tool\",\n",
    "    func=acronym,\n",
    "    description=\"A definitive look up tool for any Civil Service Acronym and Office abbreviation.\",\n",
    ")\n",
    "\n",
    "todays_date_and_time_tool = Tool(\n",
    "    name=\"Today's Date and Time Tool\",\n",
    "    func=todays_date_and_time,\n",
    "    description=\"A tool to get today's date and time.\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(acronym_tool.run(\"\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tools = [\n",
    "    python_repl_tool,\n",
    "    # wikipedia_tool,\n",
    "    acronym_tool,\n",
    "    todays_date_and_time_tool,\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "zero_shot_agent = initialize_agent(\n",
    "    agent=\"zero-shot-react-description\",\n",
    "    tools=tools,\n",
    "    llm=llm,\n",
    "    verbose=True,\n",
    "    max_iterations=5,\n",
    "    early_stopping_method=\"generate\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "memory = ConversationBufferWindowMemory(\n",
    "    memory_key=\"chat_history\", k=3, return_messages=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "retriever_tool = create_retriever_tool(\n",
    "    llm_instance.vector_store.as_retriever(search_kwargs={\"k\": 10}),\n",
    "    \"Search\",\n",
    "    \"This is the primary information search tool for documents uploaded by the user.\",\n",
    ")\n",
    "retriever_tools = [retriever_tool] + tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conversational_agent = initialize_agent(\n",
    "    agent=\"chat-conversational-react-description\",\n",
    "    tools=retriever_tools,\n",
    "    llm=llm,\n",
    "    verbose=True,\n",
    "    max_iterations=3,\n",
    "    early_stopping_method=\"generate\",\n",
    "    memory=memory,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conversational_agent(\"When did Rishi Sunak announce the AI Safety Institute?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conversational_agent(\"How many days ago was that?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "template = \"\"\"Your name is Redbox Copilot. You help people in UK Government answer questions and discover information.\n",
    "Be objective in your analysis and answers.\n",
    "Use the Redbox search tools to get source information.\n",
    "When working with time ALWAYS use the tools provided to calulate the time difference.\n",
    "Complete the objective given as best you can. You have access to the following tools:\n",
    "\n",
    "{tools}\n",
    "\n",
    "Use the following format:\n",
    "\n",
    "Question: the input question you must answer\n",
    "Thought: you should always think about what to do\n",
    "Action: the action to take, should be one of [{tool_names}]\n",
    "Action Input: the input to the action\n",
    "Observation: the result of the action\n",
    "... (this Thought/Action/Action Input/Observation can repeat N times)\n",
    "Thought: I now know the final answer\n",
    "Final Answer: the final answer to the original input question\n",
    "\n",
    "These were previous tasks you completed:\n",
    "\n",
    "\n",
    "\n",
    "Begin!\n",
    "\n",
    "Question: {input}\n",
    "{agent_scratchpad}\"\"\"\n",
    "\n",
    "\n",
    "# Set up a prompt template\n",
    "class CustomPromptTemplate(BaseChatPromptTemplate):\n",
    "    # The template to use\n",
    "    template: str\n",
    "    # The list of tools available\n",
    "    tools: List[Tool]\n",
    "\n",
    "    def format_messages(self, **kwargs) -> str:\n",
    "        # Get the intermediate steps (AgentAction, Observation tuples)\n",
    "        # Format them in a particular way\n",
    "        intermediate_steps = kwargs.pop(\"intermediate_steps\")\n",
    "        thoughts = \"\"\n",
    "        for action, observation in intermediate_steps:\n",
    "            thoughts += action.log\n",
    "            thoughts += f\"\\nObservation: {observation}\\nThought: \"\n",
    "        # Set the agent_scratchpad variable to that value\n",
    "        kwargs[\"agent_scratchpad\"] = thoughts\n",
    "        # Create a tools variable from the list of tools provided\n",
    "        kwargs[\"tools\"] = \"\\n\".join(\n",
    "            [f\"{tool.name}: {tool.description}\" for tool in self.tools]\n",
    "        )\n",
    "        # Create a list of tool names for the tools provided\n",
    "        kwargs[\"tool_names\"] = \", \".join([tool.name for tool in self.tools])\n",
    "        formatted = self.template.format(**kwargs)\n",
    "        return [HumanMessage(content=formatted)]\n",
    "\n",
    "\n",
    "prompt = CustomPromptTemplate(\n",
    "    template=template,\n",
    "    tools=retriever_tools,\n",
    "    # This omits the `agent_scratchpad`, `tools`, and `tool_names` variables because those are generated dynamically\n",
    "    # This includes the `intermediate_steps` variable because that is needed\n",
    "    input_variables=[\"input\", \"intermediate_steps\"],\n",
    ")\n",
    "\n",
    "\n",
    "class CustomOutputParser(AgentOutputParser):\n",
    "    def parse(self, llm_output: str) -> Union[AgentAction, AgentFinish]:\n",
    "        # Check if agent should finish\n",
    "        if \"Final Answer:\" in llm_output:\n",
    "            return AgentFinish(\n",
    "                # Return values is generally always a dictionary with a single `output` key\n",
    "                # It is not recommended to try anything else at the moment :)\n",
    "                return_values={\"output\": llm_output.split(\"Final Answer:\")[-1].strip()},\n",
    "                log=llm_output,\n",
    "            )\n",
    "        # Parse out the action and action input\n",
    "        regex = r\"Action\\s*\\d*\\s*:(.*?)\\nAction\\s*\\d*\\s*Input\\s*\\d*\\s*:[\\s]*(.*)\"\n",
    "        match = re.search(regex, llm_output, re.DOTALL)\n",
    "        if not match:\n",
    "            raise ValueError(f\"Could not parse LLM output: `{llm_output}`\")\n",
    "        action = match.group(1).strip()\n",
    "        action_input = match.group(2)\n",
    "        # Return the action and action input\n",
    "        return AgentAction(\n",
    "            tool=action, tool_input=action_input.strip(\" \").strip('\"'), log=llm_output\n",
    "        )\n",
    "\n",
    "\n",
    "output_parser = CustomOutputParser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm_chain = LLMChain(llm=llm, prompt=prompt)\n",
    "\n",
    "tool_names = [tool.name for tool in retriever_tools]\n",
    "\n",
    "agent = LLMSingleActionAgent(\n",
    "    llm_chain=llm_chain,\n",
    "    output_parser=output_parser,\n",
    "    stop=[\"\\nObservation:\"],\n",
    "    allowed_tools=tool_names,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "memory = ConversationBufferWindowMemory(\n",
    "    memory_key=\"chat_history\", k=3, return_messages=True\n",
    ")\n",
    "agent_executor = AgentExecutor.from_agent_and_tools(\n",
    "    agent=agent, tools=retriever_tools, verbose=True, memory=memory\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "agent_executor.run(\"How many years until Artificial General Intelligence?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
