{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add autoreload\n",
    "%reload_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.auto import tqdm\n",
    "import pandas as pd\n",
    "import typing as t\n",
    "import jsonlines\n",
    "import pickle\n",
    "from pathlib import Path\n",
    "from uuid import UUID\n",
    "\n",
    "from langchain.document_loaders import DirectoryLoader\n",
    "from langchain.schema import Document\n",
    "from langchain_openai import ChatOpenAI, OpenAIEmbeddings\n",
    "\n",
    "from ragas.testset.generator import TestsetGenerator\n",
    "from ragas.testset.evolutions import simple, reasoning, multi_context\n",
    "\n",
    "from redbox.model_db import SentenceTransformerDB\n",
    "from redbox.models import Settings\n",
    "from redbox.models.settings import ElasticLocalSettings\n",
    "from redbox.parsing import chunk_file\n",
    "from redbox.models.file import File, Chunk\n",
    "\n",
    "from mypy_boto3_s3.client import S3Client\n",
    "\n",
    "from dotenv import find_dotenv, load_dotenv\n",
    "\n",
    "_ = load_dotenv(find_dotenv())\n",
    "\n",
    "pd.set_option(\"display.max_colwidth\", None)\n",
    "\n",
    "ENV = Settings(minio_host=\"localhost\", elastic=ElasticLocalSettings(host=\"localhost\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "☝️⚠️ _expand cell to run imports_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create evaluation dataset for Redbox RAG chat  <a class=\"anchor\" id=\"title\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Evaluate Redbox RAG chat on one stable, numbered version of these data**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Before running this notebook**\n",
    "\n",
    "Set the version of the evaluation dataset you are creating **[HERE](#setversion)**.\n",
    "\n",
    "Run the evaluation backend with `make eval_backend`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Table of Contents <a class=\"anchor\" id=\"toc\"></a>\n",
    "\n",
    "* [Overview](#overview)\n",
    "* Process\n",
    "    1. [Set version of the evaluation dataset (and other global variables)](#setversion)\n",
    "    2. [Select files for creating evaluation dataset](#files)\n",
    "    3. [Generate evaluation dataset](#ragas)\n",
    "    4. [Save evaluation dataset](#save)\n",
    "    5. [Pre-embed the documents](#embed)\n",
    "* [Troubleshooting](#troubleshooting)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Overview <a class=\"anchor\" id=\"overview\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is really important to version the evaluations we are doing, including the input data used to generate evaluation datasets.\n",
    "\n",
    "This notebook uses the files you select in combination with the RAGAS framework to generate synthetic data. Two different LLMs are used, one for the 'generator' and one for the 'critic'.\n",
    "\n",
    "Please be aware the generating synthetic data will incur LLM API costs.\n",
    "\n",
    "The purpose of this note book is to **create a filesystem with a versioned dataset**. This means:\n",
    "\n",
    "* Raw files, like documents nad PDFs\n",
    "* An evaluation dataset, containing questions and answers\n",
    "* Embedded chunks for those raw files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is a troubleshooting section at the end of this notebook [Troubleshooting](#troubleshooting)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Back to top](#title)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  1. Set global variables <a class=\"anchor\" id=\"setversion\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Evaluate Redbox RAG chat on one stable, numbered version of these data**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Set the version of the evaluation dataset you will be creating in this notebook in the cell below**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_VERSION = \"0.1.0\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Embedding and retrieval is locked to a particular embedding model, which should be tied to a single index in the vector stoer. Here we default to the `EMBEDDING_MODEL` environment variable, which will match production if set via `.env.example`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL = ENV.embedding_model\n",
    "INDEX = f\"{DATA_VERSION}-{MODEL}\".lower()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run the cell below to set up the required folder structure (it will not overwrite folders and files if they already exist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ROOT = Path.cwd().parents[1]\n",
    "EVALUATION_DIR = ROOT / \"notebooks/evaluation\"\n",
    "\n",
    "V_ROOT = EVALUATION_DIR / f\"data/{DATA_VERSION}\"\n",
    "V_RAW = V_ROOT / \"raw\"\n",
    "V_SYNTHETIC = V_ROOT / \"synthetic\"\n",
    "V_CHUNKS = V_ROOT / \"chunks\"\n",
    "V_RESULTS = V_ROOT / \"results\"\n",
    "V_EMBEDDINGS = V_ROOT / \"embeddings\"\n",
    "\n",
    "V_ROOT.mkdir(parents=True, exist_ok=True)\n",
    "V_RAW.mkdir(parents=True, exist_ok=True)\n",
    "V_SYNTHETIC.mkdir(parents=True, exist_ok=True)\n",
    "V_CHUNKS.mkdir(parents=True, exist_ok=True)\n",
    "V_RESULTS.mkdir(parents=True, exist_ok=True)\n",
    "V_EMBEDDINGS.mkdir(parents=True, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It's helpful for all calls to share a dummy user. Set that here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "USER_UUID = UUID(\"aaaaaaaa-aaaa-aaaa-aaaa-aaaaaaaaaaaa\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set up the clients to connect to the backend."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "S3_CLIENT = ENV.s3_client()\n",
    "ES_CLIENT = ENV.elasticsearch_client()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Back to top](#title)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Select files that you will use to generate versioned evaluation dataset   <a class=\"anchor\" id=\"files\"></a>\n",
    "\n",
    "Now copy all the files you want to use to generate **THIS VERSION** of the evaluation dataset into `notebooks/evaluation/data/{DATA_VERSION}/raw/`\n",
    "\n",
    "Also upload these files to shared Google Drive and the corresponding version number/location"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Back to top](#title)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Synthetically generate evaluation dataset <a class=\"anchor\" id=\"ragas\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "RAGAS generating a synthetic test set detailed [HERE](https://docs.ragas.io/en/stable/getstarted/testset_generation.html). Perhaps not as SOTA as DeepEval (validate!), but it creates `input` AND `expected_output` for us. \n",
    "\n",
    "So we are not generating input questions based on our chunking strategy, however, we are using the same files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Takes about 4 minutes for 4 docs. Consider Langchain `unstructured`\n",
    "loader = DirectoryLoader(V_RAW)\n",
    "documents = loader.load()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save Langchain documents for future use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_docs_to_jsonl(documents: t.Iterable[Document], file_path: str) -> None:\n",
    "    with jsonlines.open(file_path, mode=\"w\") as writer:\n",
    "        for doc in documents:\n",
    "            writer.write(doc.dict())\n",
    "\n",
    "\n",
    "def load_docs_from_jsonl(file_path) -> t.Iterable[Document]:\n",
    "    documents = []\n",
    "    with jsonlines.open(file_path, mode=\"r\") as reader:\n",
    "        for doc in reader:\n",
    "            documents.append(Document(**doc))\n",
    "    return documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_docs_to_jsonl(documents, V_CHUNKS / \"documents.jsonl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate RAGAS dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RAGAS generator with openai models\n",
    "generator_llm = ChatOpenAI(model=\"gpt-3.5-turbo\")  # to match core-api\n",
    "critic_llm = ChatOpenAI(model=\"gpt-4o\")  # cheaper model with similar performance\n",
    "embeddings = OpenAIEmbeddings()\n",
    "\n",
    "generator = TestsetGenerator.from_langchain(generator_llm, critic_llm, embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate testset\n",
    "testset = generator.generate_with_langchain_docs(\n",
    "    documents, test_size=10, distributions={simple: 0.4, reasoning: 0.3, multi_context: 0.3}\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Back to top](#title)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Save evaluation dataset <a class=\"anchor\" id=\"save\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f\"{V_SYNTHETIC}/ragas_testset.pkl\", \"wb\") as f:\n",
    "    pickle.dump(testset, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convert dataframe into a DeepEval compatible CSV & save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testset_df = testset.to_pandas()\n",
    "\n",
    "# Rename the columns\n",
    "new_column_names = {\n",
    "    \"question\": \"input\",\n",
    "    \"contexts\": \"context\",\n",
    "    \"ground_truth\": \"expected_output\",\n",
    "    # Add more column names here\n",
    "}\n",
    "\n",
    "testset_df_renamed = testset_df.rename(columns=new_column_names)\n",
    "\n",
    "#  DeepEval dataset format requires an 'actual_output' column\n",
    "testset_df_renamed[\"actual_output\"] = \"\"\n",
    "testset_df_renamed = testset_df_renamed.drop([\"evolution_type\", \"metadata\", \"episode_done\"], axis=1)\n",
    "\n",
    "# Convert all columns to string & drop NaN - otherwise DeepEval will throw an Pydantic validation error\n",
    "testset_df_renamed = testset_df_renamed.astype(str)\n",
    "testset_df_renamed = testset_df_renamed.dropna()\n",
    "\n",
    "# save as CSV\n",
    "testset_df_renamed.to_csv(f\"{V_SYNTHETIC}/ragas_synthetic_data.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (Optional) View top 5 rows of synthetically generated data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testset_df_renamed.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Back to top](#title)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Pre-embed the documents for other users <a class=\"anchor\" id=\"embed\"></a>\n",
    "\n",
    "Embeddings take a while. Here we show how to compute and save them for other users.\n",
    "\n",
    "For now we use the chunking strategy from `worker/`, and embed with any models we choose.\n",
    "\n",
    "Ensure the necessary services are running with `make eval_backend`, but all we really need is MinIO."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_chunks_to_jsonl(chunks: t.Iterable[Chunk], file_path: Path) -> None:\n",
    "    with jsonlines.open(file_path, mode=\"w\") as writer:\n",
    "        for chunk in chunks:\n",
    "            writer.write(chunk.model_dump_json())\n",
    "\n",
    "\n",
    "def embed_file(\n",
    "    file_path: Path,\n",
    "    data_version: str,\n",
    "    bucket_name: str,\n",
    "    model: SentenceTransformerDB,\n",
    "    user_uuid: UUID = USER_UUID,\n",
    "    s3_client: S3Client = S3_CLIENT,\n",
    ") -> list[Chunk]:\n",
    "    key = f\"{data_version}/{file_path.name}\"\n",
    "    file = File(key=key, bucket=bucket_name, creator_user_uuid=user_uuid)\n",
    "\n",
    "    # Upload to bucket\n",
    "    with open(file_path, \"rb\") as f:\n",
    "        s3_client.upload_fileobj(f, bucket_name, key)\n",
    "\n",
    "    # Chunk\n",
    "    chunks = chunk_file(file=file, s3_client=s3_client)\n",
    "\n",
    "    # Embed\n",
    "    embeddings = [embedding.embedding for embedding in model.embed_sentences([chunk.text for chunk in chunks]).data]\n",
    "\n",
    "    # Merge\n",
    "    chunks_embedded = []\n",
    "    for chunk, embedding in zip(chunks, embeddings, strict=True):\n",
    "        chunk_embedded = Chunk(\n",
    "            uuid=chunk.uuid,\n",
    "            created_datetime=chunk.created_datetime,\n",
    "            creator_user_uuid=chunk.creator_user_uuid,\n",
    "            parent_file_uuid=chunk.parent_file_uuid,\n",
    "            index=chunk.index,\n",
    "            text=chunk.text,\n",
    "            metadata=chunk.metadata,\n",
    "            embedding=embedding,\n",
    "        )\n",
    "        chunks_embedded.append(chunk_embedded)\n",
    "\n",
    "    return chunks_embedded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_embedded_files = []\n",
    "\n",
    "for file_path in V_RAW.glob(\"*.*\"):\n",
    "    file_chunks_embedded = embed_file(\n",
    "        file_path=file_path,\n",
    "        data_version=DATA_VERSION,\n",
    "        bucket_name=ENV.bucket_name,\n",
    "        model=SentenceTransformerDB(embedding_model_name=MODEL),\n",
    "    )\n",
    "    all_embedded_files += file_chunks_embedded\n",
    "\n",
    "save_chunks_to_jsonl(chunks=all_embedded_files, file_path=V_EMBEDDINGS / f\"{MODEL}.jsonl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Back to top](#title)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Troubleshooting <a class=\"anchor\" id=\"troubleshooting\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Langchain DirectoryLoader Error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you run into a poppler path error and poppler is installed and can be access from your virtual environment (by running `pdfinfo -v`), then close notebook and restart the Jupyter server from the terminal where the path is correctly set (by running `code notebooks/evaluation/evaluation_dataset_generation.ipynb`) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### RAGAS synthetically generated evaluation data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have found some rows of synthetically generated evaluation data from using the RAGAS framework, includes some NaN and/or not str type, which results in an error for DeepEval metrics, as these data fail Pydantic validation.\n",
    "\n",
    "To avoid this, ensure you turn RAGAS synthetically generated evaluation data to type str and remove rows of data with NaN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### DeepEval framework"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At the moment, this notebook only loads the evaluation dataset into DeepEval from a CSV. There is a JSON import option that we are not using."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Back to top](#title)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-------"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "redbox-MiicHf1r-py3.11",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
