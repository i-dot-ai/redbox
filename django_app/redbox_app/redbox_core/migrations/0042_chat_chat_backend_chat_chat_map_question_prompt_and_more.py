# Generated by Django 5.1.1 on 2024-09-07 11:53

from django.db import migrations, models


def back_populate_ai_settings_on_chat(apps, schema_editor):
    Chat = apps.get_model("redbox_core", "Chat")
    for chat in Chat.objects.all():
        chat.max_document_tokens = chat.user.ai_settings.max_document_tokens
        chat.context_window_size = chat.user.ai_settings.context_window_size
        chat.llm_max_tokens = chat.user.ai_settings.llm_max_tokens
        chat.rag_k = chat.user.ai_settings.rag_k
        chat.rag_num_candidates = chat.user.ai_settings.rag_num_candidates
        chat.rag_desired_chunk_size = chat.user.ai_settings.rag_desired_chunk_size
        chat.elbow_filter_enabled = chat.user.ai_settings.elbow_filter_enabled
        chat.chat_system_prompt = chat.user.ai_settings.chat_system_prompt
        chat.chat_question_prompt = chat.user.ai_settings.chat_question_prompt
        chat.stuff_chunk_context_ratio = chat.user.ai_settings.stuff_chunk_context_ratio
        chat.chat_with_docs_system_prompt = chat.user.ai_settings.chat_with_docs_system_prompt
        chat.chat_with_docs_question_prompt = chat.user.ai_settings.chat_with_docs_question_prompt
        chat.chat_with_docs_reduce_system_prompt = chat.user.ai_settings.chat_with_docs_reduce_system_prompt
        chat.retrieval_system_prompt = chat.user.ai_settings.retrieval_system_prompt
        chat.retrieval_question_prompt = chat.user.ai_settings.retrieval_question_prompt
        chat.condense_system_prompt = chat.user.ai_settings.condense_system_prompt
        chat.condense_question_prompt = chat.user.ai_settings.condense_question_prompt
        chat.map_max_concurrency = chat.user.ai_settings.map_max_concurrency
        chat.chat_map_system_prompt = chat.user.ai_settings.chat_map_system_prompt
        chat.chat_map_question_prompt = chat.user.ai_settings.chat_map_question_prompt
        chat.reduce_system_prompt = chat.user.ai_settings.reduce_system_prompt
        chat.match_boost = chat.user.ai_settings.match_boost
        chat.knn_boost = chat.user.ai_settings.knn_boost
        chat.similarity_threshold = chat.user.ai_settings.similarity_threshold
        chat.chat_backend = chat.user.ai_settings.chat_backend
        chat.save()


class Migration(migrations.Migration):

    dependencies = [
        ('redbox_core', '0041_alter_aisettings_chat_backend'),
    ]

    operations = [
        migrations.AddField(
            model_name='chat',
            name='chat_backend',
            field=models.CharField(blank=True, choices=[('gpt-35-turbo-16k', 'gpt-35-turbo-16k'), ('gpt-4-turbo-2024-04-09', 'gpt-4-turbo-2024-04-09'), ('gpt-4o', 'gpt-4o'), ('anthropic.claude-3-sonnet-20240229-v1:0', 'claude-3-sonnet'), ('anthropic.claude-3-haiku-20240307-v1:0', 'claude-3-haiku')], default='gpt-4o', help_text='LLM to use in chat', max_length=64, null=True),
        ),
        migrations.AddField(
            model_name='chat',
            name='chat_map_question_prompt',
            field=models.TextField(blank=True, default='Question: {question}. \n Documents: \n {formatted_documents} \n\n Answer: ', null=True),
        ),
        migrations.AddField(
            model_name='chat',
            name='chat_map_system_prompt',
            field=models.TextField(blank=True, default='You are an AI assistant tasked with summarizing documents. Your goal is to extract the most important information and present it in a concise and coherent manner. Please follow these guidelines while summarizing: \n1) Identify and highlight key points,\n2) Avoid repetition,\n3) Ensure the summary is easy to understand,\n4) Maintain the original context and meaning.\n', null=True),
        ),
        migrations.AddField(
            model_name='chat',
            name='chat_question_prompt',
            field=models.TextField(blank=True, default='{question}\n=========\n Response: ', null=True),
        ),
        migrations.AddField(
            model_name='chat',
            name='chat_system_prompt',
            field=models.TextField(blank=True, default='You are an AI assistant called Redbox tasked with answering questions and providing information objectively.', null=True),
        ),
        migrations.AddField(
            model_name='chat',
            name='chat_with_docs_question_prompt',
            field=models.TextField(blank=True, default='Question: {question}. \n\n Documents: \n\n {formatted_documents} \n\n Answer: ', null=True),
        ),
        migrations.AddField(
            model_name='chat',
            name='chat_with_docs_reduce_system_prompt',
            field=models.TextField(blank=True, default='You are an AI assistant tasked with answering questions on user provided documents. Your goal is to answer the user question based on list of summaries in a coherent manner.Please follow these guidelines while answering the question: \n1) Identify and highlight key points,\n2) Avoid repetition,\n3) Ensure the answer is easy to understand,\n4) Maintain the original context and meaning.\n', null=True),
        ),
        migrations.AddField(
            model_name='chat',
            name='chat_with_docs_system_prompt',
            field=models.TextField(blank=True, default='You are an AI assistant called Redbox tasked with answering questions on user provided documents and providing information objectively.', null=True),
        ),
        migrations.AddField(
            model_name='chat',
            name='condense_question_prompt',
            field=models.TextField(blank=True, default='{question}\n=========\n Standalone question: ', null=True),
        ),
        migrations.AddField(
            model_name='chat',
            name='condense_system_prompt',
            field=models.TextField(blank=True, default="Given the following conversation and a follow up question, generate a follow up question to be a standalone question. You are only allowed to generate one question in response. Include sources from the chat history in the standalone question created, when they are available. If you don't know the answer, just say that you don't know, don't try to make up an answer. \n", null=True),
        ),
        migrations.AddField(
            model_name='chat',
            name='context_window_size',
            field=models.PositiveIntegerField(blank=True, default=128000, null=True),
        ),
        migrations.AddField(
            model_name='chat',
            name='elbow_filter_enabled',
            field=models.BooleanField(blank=True, default=False, null=True),
        ),
        migrations.AddField(
            model_name='chat',
            name='knn_boost',
            field=models.PositiveIntegerField(blank=True, default=1, null=True),
        ),
        migrations.AddField(
            model_name='chat',
            name='llm_max_tokens',
            field=models.PositiveIntegerField(blank=True, default=1024, null=True),
        ),
        migrations.AddField(
            model_name='chat',
            name='map_max_concurrency',
            field=models.PositiveIntegerField(blank=True, default=128, null=True),
        ),
        migrations.AddField(
            model_name='chat',
            name='match_boost',
            field=models.PositiveIntegerField(blank=True, default=1, null=True),
        ),
        migrations.AddField(
            model_name='chat',
            name='max_document_tokens',
            field=models.PositiveIntegerField(blank=True, default=1000000, null=True),
        ),
        migrations.AddField(
            model_name='chat',
            name='rag_desired_chunk_size',
            field=models.PositiveIntegerField(blank=True, default=300, null=True),
        ),
        migrations.AddField(
            model_name='chat',
            name='rag_k',
            field=models.PositiveIntegerField(blank=True, default=30, null=True),
        ),
        migrations.AddField(
            model_name='chat',
            name='rag_num_candidates',
            field=models.PositiveIntegerField(blank=True, default=10, null=True),
        ),
        migrations.AddField(
            model_name='chat',
            name='reduce_system_prompt',
            field=models.TextField(blank=True, default='You are an AI assistant tasked with summarizing documents. Your goal is to write a concise summary of list of summaries from a list of summaries in a concise and coherent manner. Please follow these guidelines while summarizing: \n1) Identify and highlight key points,\n2) Avoid repetition,\n3) Ensure the summary is easy to understand,\n4) Maintain the original context and meaning.\n', null=True),
        ),
        migrations.AddField(
            model_name='chat',
            name='retrieval_question_prompt',
            field=models.TextField(blank=True, default='{question} \n=========\n{formatted_documents}\n=========\nFINAL ANSWER: ', null=True),
        ),
        migrations.AddField(
            model_name='chat',
            name='retrieval_system_prompt',
            field=models.TextField(blank=True, default="Given the following conversation and extracted parts of a long document and a question, create a final answer. \nIf you don't know the answer, just say that you don't know. Don't try to make up an answer. If a user asks for a particular format to be returned, such as bullet points, then please use that format. If a user asks for bullet points you MUST give bullet points. If the user asks for a specific number or range of bullet points you MUST give that number of bullet points. \nUse **bold** to highlight the most question relevant parts in your response. If dealing dealing with lots of data return it in markdown table format. ", null=True),
        ),
        migrations.AddField(
            model_name='chat',
            name='similarity_threshold',
            field=models.PositiveIntegerField(blank=True, default=0, null=True),
        ),
        migrations.AddField(
            model_name='chat',
            name='stuff_chunk_context_ratio',
            field=models.FloatField(blank=True, default=0.75, null=True),
        ),
        migrations.RunPython(back_populate_ai_settings_on_chat, migrations.RunPython.noop),
        migrations.AlterField(
            model_name='chat',
            name='chat_backend',
            field=models.CharField(
                choices=[('gpt-35-turbo-16k', 'gpt-35-turbo-16k'), ('gpt-4-turbo-2024-04-09', 'gpt-4-turbo-2024-04-09'),
                         ('gpt-4o', 'gpt-4o'), ('anthropic.claude-3-sonnet-20240229-v1:0', 'claude-3-sonnet'),
                         ('anthropic.claude-3-haiku-20240307-v1:0', 'claude-3-haiku')], default='gpt-4o',
                help_text='LLM to use in chat', max_length=64),
        ),
        migrations.AlterField(
            model_name='chat',
            name='chat_map_question_prompt',
            field=models.TextField(
                default='Question: {question}. \n Documents: \n {formatted_documents} \n\n Answer: '),
        ),
        migrations.AlterField(
            model_name='chat',
            name='chat_map_system_prompt',
            field=models.TextField(
                default='You are an AI assistant tasked with summarizing documents. Your goal is to extract the most important information and present it in a concise and coherent manner. Please follow these guidelines while summarizing: \n1) Identify and highlight key points,\n2) Avoid repetition,\n3) Ensure the summary is easy to understand,\n4) Maintain the original context and meaning.\n'),
        ),
        migrations.AlterField(
            model_name='chat',
            name='chat_question_prompt',
            field=models.TextField(default='{question}\n=========\n Response: '),
        ),
        migrations.AlterField(
            model_name='chat',
            name='chat_system_prompt',
            field=models.TextField(
                default='You are an AI assistant called Redbox tasked with answering questions and providing information objectively.'),
        ),
        migrations.AlterField(
            model_name='chat',
            name='chat_with_docs_question_prompt',
            field=models.TextField(
                default='Question: {question}. \n\n Documents: \n\n {formatted_documents} \n\n Answer: '),
        ),
        migrations.AlterField(
            model_name='chat',
            name='chat_with_docs_reduce_system_prompt',
            field=models.TextField(
                default='You are an AI assistant tasked with answering questions on user provided documents. Your goal is to answer the user question based on list of summaries in a coherent manner.Please follow these guidelines while answering the question: \n1) Identify and highlight key points,\n2) Avoid repetition,\n3) Ensure the answer is easy to understand,\n4) Maintain the original context and meaning.\n'),
        ),
        migrations.AlterField(
            model_name='chat',
            name='chat_with_docs_system_prompt',
            field=models.TextField(
                default='You are an AI assistant called Redbox tasked with answering questions on user provided documents and providing information objectively.'),
        ),
        migrations.AlterField(
            model_name='chat',
            name='condense_question_prompt',
            field=models.TextField(default='{question}\n=========\n Standalone question: '),
        ),
        migrations.AlterField(
            model_name='chat',
            name='condense_system_prompt',
            field=models.TextField(
                default="Given the following conversation and a follow up question, generate a follow up question to be a standalone question. You are only allowed to generate one question in response. Include sources from the chat history in the standalone question created, when they are available. If you don't know the answer, just say that you don't know, don't try to make up an answer. \n"),
        ),
        migrations.AlterField(
            model_name='chat',
            name='context_window_size',
            field=models.PositiveIntegerField(default=128000),
        ),
        migrations.AlterField(
            model_name='chat',
            name='elbow_filter_enabled',
            field=models.BooleanField(default=False),
        ),
        migrations.AlterField(
            model_name='chat',
            name='knn_boost',
            field=models.PositiveIntegerField(default=1),
        ),
        migrations.AlterField(
            model_name='chat',
            name='llm_max_tokens',
            field=models.PositiveIntegerField(default=1024),
        ),
        migrations.AlterField(
            model_name='chat',
            name='map_max_concurrency',
            field=models.PositiveIntegerField(default=128),
        ),
        migrations.AlterField(
            model_name='chat',
            name='match_boost',
            field=models.PositiveIntegerField(default=1),
        ),
        migrations.AlterField(
            model_name='chat',
            name='rag_desired_chunk_size',
            field=models.PositiveIntegerField(default=300),
        ),
        migrations.AlterField(
            model_name='chat',
            name='rag_k',
            field=models.PositiveIntegerField(default=30),
        ),
        migrations.AlterField(
            model_name='chat',
            name='rag_num_candidates',
            field=models.PositiveIntegerField(default=10),
        ),
        migrations.AlterField(
            model_name='chat',
            name='reduce_system_prompt',
            field=models.TextField(
                default='You are an AI assistant tasked with summarizing documents. Your goal is to write a concise summary of list of summaries from a list of summaries in a concise and coherent manner. Please follow these guidelines while summarizing: \n1) Identify and highlight key points,\n2) Avoid repetition,\n3) Ensure the summary is easy to understand,\n4) Maintain the original context and meaning.\n'),
        ),
        migrations.AlterField(
            model_name='chat',
            name='retrieval_question_prompt',
            field=models.TextField(default='{question} \n=========\n{formatted_documents}\n=========\nFINAL ANSWER: '),
        ),
        migrations.AlterField(
            model_name='chat',
            name='retrieval_system_prompt',
            field=models.TextField(
                default="Given the following conversation and extracted parts of a long document and a question, create a final answer. \nIf you don't know the answer, just say that you don't know. Don't try to make up an answer. If a user asks for a particular format to be returned, such as bullet points, then please use that format. If a user asks for bullet points you MUST give bullet points. If the user asks for a specific number or range of bullet points you MUST give that number of bullet points. \nUse **bold** to highlight the most question relevant parts in your response. If dealing dealing with lots of data return it in markdown table format. "),
        ),
        migrations.AlterField(
            model_name='chat',
            name='similarity_threshold',
            field=models.PositiveIntegerField(default=0),
        ),
        migrations.AlterField(
            model_name='chat',
            name='stuff_chunk_context_ratio',
            field=models.FloatField(default=0.75),
        ),

    ]
